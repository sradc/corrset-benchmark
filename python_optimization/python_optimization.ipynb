{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- line_profiler is used for relative speeds of lines, but slows down the overall execution, that's why iteration speed is measured separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import io\n",
    "from math import sqrt\n",
    "import numba\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from pandas import IndexSlice as islice\n",
    "import time\n",
    "import numpy as np\n",
    "import line_profiler\n",
    "\n",
    "MAX_ITER = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"data-large.json\")\n",
    "\n",
    "\n",
    "def profile_func(outer_func, func_to_profile) -> str:\n",
    "    lp = line_profiler.LineProfiler()\n",
    "    outer_func_with_profiler = lp(outer_func)\n",
    "    lp.add_function(func_to_profile)\n",
    "    outer_func_with_profiler()\n",
    "    stream = io.StringIO()\n",
    "    lp.print_stats(stream=stream)\n",
    "    report = stream.getvalue()\n",
    "    # Format report string\n",
    "    s = \"\"\n",
    "    # Get first table of report\n",
    "    add = False\n",
    "    for line in report.split(\"\\n\"):\n",
    "        if f\"Function: {func_to_profile.__name__}\" in line:\n",
    "            add = True\n",
    "        if add:\n",
    "            s += line + \"\\n\"\n",
    "        if add and \"Total time\" in line:\n",
    "            break\n",
    "    # Get only the % Time column onwards\n",
    "    start_idx = s.find(\"% Time\")\n",
    "    for line in s.split(\"\\n\"):\n",
    "        if \"Line #\" in line:\n",
    "            start_idx = line.index(\"% Time\")\n",
    "            break\n",
    "    s = \"\\n\".join(x[start_idx:] for x in s.split(\"\\n\"))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_corrset(data, K, max_iter=1000):\n",
    "    qs_combinations = itertools.islice(\n",
    "        itertools.combinations(data.question.unique(), K), max_iter\n",
    "    )\n",
    "    q_to_score = data.set_index([\"question\", \"user\"])\n",
    "    grand_totals = data.groupby(\"user\").score.sum().rename(\"grand_total\")\n",
    "    start = time.time()\n",
    "    corrs = compute_corrs(qs_combinations, q_to_score, grand_totals, K)\n",
    "    avg_iter_time_secs = (time.time() - start) / max_iter\n",
    "    corrs = pd.DataFrame(corrs)\n",
    "    return corrs, avg_iter_time_secs\n",
    "\n",
    "\n",
    "def compute_corrs(qs_combinations, q_to_score, grand_totals, K):\n",
    "    result = []\n",
    "    for qs in qs_combinations:\n",
    "        qs_data = q_to_score.loc[islice[qs, :], :].swaplevel()\n",
    "        answered_all = qs_data.groupby(level=[0]).size() == K\n",
    "        answered_all = answered_all[answered_all].index\n",
    "        qs_total = (\n",
    "            qs_data.loc[islice[answered_all, :]]\n",
    "            .groupby(level=[0])\n",
    "            .sum()\n",
    "            .rename(columns={\"score\": \"qs\"})\n",
    "        )\n",
    "        r = qs_total.join(grand_totals).corr().qs.grand_total\n",
    "        result.append({\"qs\": qs, \"r\": r})\n",
    "    return result\n",
    "\n",
    "\n",
    "print(f\"Computing times for baseline...\")\n",
    "corrs_baseline, avg_iter_time_secs_baseline = k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "outer_func = lambda: k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "s = profile_func(outer_func, compute_corrs)\n",
    "print(s.strip())\n",
    "print(f\"\\nAverage time per iteration:   {avg_iter_time_secs_baseline} seconds\")\n",
    "print(\n",
    "    f\"Speedup over baseline:        {avg_iter_time_secs_baseline/avg_iter_time_secs_baseline:0.1f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_corrset(data, K, max_iter=1000):\n",
    "    qs_combinations = itertools.islice(\n",
    "        itertools.combinations(data.question.unique(), K), max_iter\n",
    "    )\n",
    "    users_who_answered_q = {q: set() for q in data.question.unique()}\n",
    "    for q, u in data[[\"question\", \"user\"]].itertuples(index=False):\n",
    "        users_who_answered_q[q].add(u)\n",
    "    q_to_score = data.set_index([\"question\", \"user\"])\n",
    "    grand_totals = data.groupby(\"user\").score.sum().rename(\"grand_total\")\n",
    "    start = time.time()\n",
    "    corrs = compute_corrs(\n",
    "        qs_combinations, users_who_answered_q, q_to_score, grand_totals\n",
    "    )\n",
    "    avg_iter_time_secs = (time.time() - start) / max_iter\n",
    "    corrs = pd.DataFrame(corrs)\n",
    "    return corrs, avg_iter_time_secs\n",
    "\n",
    "\n",
    "def compute_corrs(qs_combinations, users_who_answered_q, q_to_score, grand_totals):\n",
    "    result = []\n",
    "    for qs in qs_combinations:\n",
    "        user_sets_for_qs = [users_who_answered_q[q] for q in qs]\n",
    "        answered_all = set.intersection(*user_sets_for_qs)\n",
    "        qs_data = q_to_score.loc[islice[qs, :], :].swaplevel()\n",
    "        qs_total = (\n",
    "            qs_data.loc[islice[list(answered_all), :]]\n",
    "            .groupby(level=[0])\n",
    "            .sum()\n",
    "            .rename(columns={\"score\": \"qs\"})\n",
    "        )\n",
    "        r = qs_total.join(grand_totals).corr().qs.grand_total\n",
    "        result.append({\"qs\": qs, \"r\": r})\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Running optimization 1 - using sets instead of groupby\")\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "assert np.allclose(corrs_baseline.r, corrs.r, equal_nan=True)\n",
    "outer_func = lambda: k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "s = profile_func(outer_func, compute_corrs)\n",
    "print(s.strip())\n",
    "print(f\"\\nAverage time per iteration:   {avg_iter_time_secs} seconds\")\n",
    "print(\n",
    "    f\"Speedup over baseline:        {avg_iter_time_secs_baseline/avg_iter_time_secs:0.1f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_corrset(data, K, max_iter=1000):\n",
    "    qs_combinations = itertools.islice(\n",
    "        itertools.combinations(data.question.unique(), K), max_iter\n",
    "    )\n",
    "    users_who_answered_q = {q: set() for q in data.question.unique()}\n",
    "    for q, u in data[[\"question\", \"user\"]].itertuples(index=False):\n",
    "        users_who_answered_q[q].add(u)\n",
    "    score_dict = {\n",
    "        (q, u): s\n",
    "        for q, u, s in data[[\"question\", \"user\", \"score\"]].itertuples(index=False)\n",
    "    }\n",
    "    grand_totals = data.groupby(\"user\").score.sum().rename(\"grand_total\")\n",
    "    start = time.time()\n",
    "    corrs = compute_corrs(\n",
    "        qs_combinations, users_who_answered_q, score_dict, grand_totals\n",
    "    )\n",
    "    avg_iter_time_secs = (time.time() - start) / max_iter\n",
    "    corrs = pd.DataFrame(corrs)\n",
    "    return corrs, avg_iter_time_secs\n",
    "\n",
    "\n",
    "def compute_corrs(qs_combinations, users_who_answered_q, score_dict, grand_totals):\n",
    "    result = []\n",
    "    for qs in qs_combinations:\n",
    "        user_sets_for_qs = [users_who_answered_q[q] for q in qs]\n",
    "        answered_all = set.intersection(*user_sets_for_qs)\n",
    "        qs_total = {u: sum(score_dict[q, u] for q in qs) for u in answered_all}\n",
    "        qs_total = pd.DataFrame.from_dict(qs_total, orient=\"index\", columns=[\"qs\"])\n",
    "        qs_total.index.name = \"user\"\n",
    "        r = qs_total.join(grand_totals).corr().qs.grand_total\n",
    "        result.append({\"qs\": qs, \"r\": r})\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Running optimization 2 - using dicts for scores\")\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "assert np.allclose(corrs_baseline.r, corrs.r, equal_nan=True)\n",
    "outer_func = lambda: k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "s = profile_func(outer_func, compute_corrs)\n",
    "print(s.strip())\n",
    "print(f\"\\nAverage time per iteration:   {avg_iter_time_secs} seconds\")\n",
    "print(\n",
    "    f\"Speedup over baseline:        {avg_iter_time_secs_baseline/avg_iter_time_secs:0.1f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_corrset(data, K, max_iter=1000):\n",
    "    qs_combinations = itertools.islice(\n",
    "        itertools.combinations(data.question.unique(), K), max_iter\n",
    "    )\n",
    "    users_who_answered_q = {q: set() for q in data.question.unique()}\n",
    "    for q, u in data[[\"question\", \"user\"]].itertuples(index=False):\n",
    "        users_who_answered_q[q].add(u)\n",
    "    score_dict = {\n",
    "        (q, u): s\n",
    "        for q, u, s in data[[\"question\", \"user\", \"score\"]].itertuples(index=False)\n",
    "    }\n",
    "    grand_totals = data.groupby(\"user\").score.sum().rename(\"grand_total\").to_dict()\n",
    "    start = time.time()\n",
    "    corrs = compute_corrs(\n",
    "        qs_combinations, users_who_answered_q, score_dict, grand_totals\n",
    "    )\n",
    "    avg_iter_time_secs = (time.time() - start) / max_iter\n",
    "    corrs = pd.DataFrame(corrs)\n",
    "    return corrs, avg_iter_time_secs\n",
    "\n",
    "\n",
    "def compute_corrs(qs_combinations, users_who_answered_q, score_dict, grand_totals):\n",
    "    result = []\n",
    "    for qs in qs_combinations:\n",
    "        user_sets_for_qs = [users_who_answered_q[q] for q in qs]\n",
    "        answered_all = set.intersection(*user_sets_for_qs)\n",
    "        qs_total = [sum(score_dict[q, u] for q in qs) for u in answered_all]\n",
    "        user_grand_total = [grand_totals[u] for u in answered_all]\n",
    "        r = np.corrcoef(qs_total, user_grand_total)[0, 1]\n",
    "        result.append({\"qs\": qs, \"r\": r})\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Running optimization 3 - using dicts for grand totals\")\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "assert np.allclose(corrs_baseline.r, corrs.r, equal_nan=True)\n",
    "outer_func = lambda: k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "s = profile_func(outer_func, compute_corrs)\n",
    "print(s.strip())\n",
    "print(f\"\\nAverage time per iteration:   {avg_iter_time_secs} seconds\")\n",
    "print(\n",
    "    f\"Speedup over baseline:        {avg_iter_time_secs_baseline/avg_iter_time_secs:0.1f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_corrset(data, K, max_iter=1000):\n",
    "    data = data.copy()\n",
    "    data.user = data.user.map({u: i for i, u in enumerate(data.user.unique())})\n",
    "    data.question = data.question.map(\n",
    "        {q: i for i, q in enumerate(data.question.unique())}\n",
    "    )\n",
    "    qs_combinations = itertools.islice(\n",
    "        itertools.combinations(data.question.unique(), K), max_iter\n",
    "    )\n",
    "    users_who_answered_q = {q: set() for q in data.question.unique()}\n",
    "    for q, u in data[[\"question\", \"user\"]].itertuples(index=False):\n",
    "        users_who_answered_q[q].add(u)\n",
    "    score_dict = {\n",
    "        (q, u): s\n",
    "        for q, u, s in data[[\"question\", \"user\", \"score\"]].itertuples(index=False)\n",
    "    }\n",
    "    grand_totals = data.groupby(\"user\").score.sum().rename(\"grand_total\").to_dict()\n",
    "    start = time.time()\n",
    "    corrs = compute_corrs(\n",
    "        qs_combinations, users_who_answered_q, score_dict, grand_totals\n",
    "    )\n",
    "    avg_iter_time_secs = (time.time() - start) / max_iter\n",
    "    corrs = pd.DataFrame(corrs)\n",
    "    return corrs, avg_iter_time_secs\n",
    "\n",
    "\n",
    "def compute_corrs(qs_combinations, users_who_answered_q, score_dict, grand_totals):\n",
    "    result = []\n",
    "    for qs in qs_combinations:\n",
    "        user_sets_for_qs = [users_who_answered_q[q] for q in qs]\n",
    "        answered_all = set.intersection(*user_sets_for_qs)\n",
    "        qs_total = [sum(score_dict[q, u] for q in qs) for u in answered_all]\n",
    "        user_grand_total = [grand_totals[u] for u in answered_all]\n",
    "        r = np.corrcoef(qs_total, user_grand_total)[0, 1]\n",
    "        result.append({\"qs\": qs, \"r\": r})\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Running optimization 4 - ints instead of strings for user/questions\")\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "assert np.allclose(corrs_baseline.r, corrs.r, equal_nan=True)\n",
    "outer_func = lambda: k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "s = profile_func(outer_func, compute_corrs)\n",
    "print(s.strip())\n",
    "print(f\"\\nAverage time per iteration:   {avg_iter_time_secs} seconds\")\n",
    "print(\n",
    "    f\"Speedup over baseline:        {avg_iter_time_secs_baseline/avg_iter_time_secs:0.1f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_corrset(data, K, max_iter=1000):\n",
    "    data = data.copy()\n",
    "    data.user = data.user.map({u: i for i, u in enumerate(data.user.unique())})\n",
    "    data.question = data.question.map(\n",
    "        {q: i for i, q in enumerate(data.question.unique())}\n",
    "    )\n",
    "    qs_combinations = itertools.islice(\n",
    "        itertools.combinations(data.question.unique(), K), max_iter\n",
    "    )\n",
    "    users_who_answered_q = np.zeros(\n",
    "        (len(data.question.unique()), len(data.user.unique())), dtype=np.bool_\n",
    "    )\n",
    "    for q, u in data[[\"question\", \"user\"]].itertuples(index=False):\n",
    "        users_who_answered_q[q, u] = True\n",
    "    score_dict = {\n",
    "        (q, u): s\n",
    "        for q, u, s in data[[\"question\", \"user\", \"score\"]].itertuples(index=False)\n",
    "    }\n",
    "    grand_totals = data.groupby(\"user\").score.sum().rename(\"grand_total\").to_dict()\n",
    "    start = time.time()\n",
    "    corrs = compute_corrs(\n",
    "        qs_combinations, users_who_answered_q, score_dict, grand_totals\n",
    "    )\n",
    "    avg_iter_time_secs = (time.time() - start) / max_iter\n",
    "    corrs = pd.DataFrame(corrs)\n",
    "    return corrs, avg_iter_time_secs\n",
    "\n",
    "\n",
    "def compute_corrs(qs_combinations, users_who_answered_q, score_dict, grand_totals):\n",
    "    result = []\n",
    "    for qs in qs_combinations:\n",
    "        user_sets_for_qs = users_who_answered_q[qs, :]  # numpy indexing\n",
    "        answered_all = np.logical_and.reduce(user_sets_for_qs)\n",
    "        answered_all = np.where(answered_all)[0]\n",
    "        qs_total = [sum(score_dict[q, u] for q in qs) for u in answered_all]\n",
    "        user_grand_total = [grand_totals[u] for u in answered_all]\n",
    "        r = np.corrcoef(qs_total, user_grand_total)[0, 1]\n",
    "        result.append({\"qs\": qs, \"r\": r})\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Running optimization 5 - numpy boolean array for users who answered\")\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "assert np.allclose(corrs_baseline.r, corrs.r, equal_nan=True)\n",
    "outer_func = lambda: k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "s = profile_func(outer_func, compute_corrs)\n",
    "print(s.strip())\n",
    "print(f\"\\nAverage time per iteration:   {avg_iter_time_secs} seconds\")\n",
    "print(\n",
    "    f\"Speedup over baseline:        {avg_iter_time_secs_baseline/avg_iter_time_secs:0.1f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_corrset(data, K, max_iter=1000):\n",
    "    data = data.copy()\n",
    "    data.user = data.user.map({u: i for i, u in enumerate(data.user.unique())})\n",
    "    data.question = data.question.map(\n",
    "        {q: i for i, q in enumerate(data.question.unique())}\n",
    "    )\n",
    "    qs_combinations = itertools.islice(\n",
    "        itertools.combinations(data.question.unique(), K), max_iter\n",
    "    )\n",
    "    users_who_answered_q = np.zeros(\n",
    "        (len(data.question.unique()), len(data.user.unique())), dtype=np.bool_\n",
    "    )\n",
    "    for q, u in data[[\"question\", \"user\"]].itertuples(index=False):\n",
    "        users_who_answered_q[q, u] = True\n",
    "\n",
    "    score_matrix = np.zeros(\n",
    "        (len(data.user.unique()), len(data.question.unique())), dtype=np.float64\n",
    "    )\n",
    "    for q, u, s in data[[\"question\", \"user\", \"score\"]].itertuples(index=False):\n",
    "        score_matrix[u, q] = s\n",
    "\n",
    "    grand_totals = data.groupby(\"user\").score.sum().rename(\"grand_total\").to_dict()\n",
    "    start = time.time()\n",
    "    corrs = compute_corrs(\n",
    "        qs_combinations, users_who_answered_q, score_matrix, grand_totals\n",
    "    )\n",
    "    avg_iter_time_secs = (time.time() - start) / max_iter\n",
    "    corrs = pd.DataFrame(corrs)\n",
    "    return corrs, avg_iter_time_secs\n",
    "\n",
    "\n",
    "def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):\n",
    "    result = []\n",
    "    for qs in qs_combinations:\n",
    "        user_sets_for_qs = users_who_answered_q[qs, :]\n",
    "        answered_all = np.logical_and.reduce(user_sets_for_qs)\n",
    "        answered_all = np.where(answered_all)[0]\n",
    "        qs_total = score_matrix[answered_all, :][:, qs].sum(axis=1)\n",
    "        user_grand_total = [grand_totals[u] for u in answered_all]\n",
    "        r = np.corrcoef(qs_total, user_grand_total)[0, 1]\n",
    "        result.append({\"qs\": qs, \"r\": r})\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Running optimization 6 - score matrix instead of score dict\")\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "assert np.allclose(corrs_baseline.r, corrs.r, equal_nan=True)\n",
    "outer_func = lambda: k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "s = profile_func(outer_func, compute_corrs)\n",
    "print(s.strip())\n",
    "print(f\"\\nAverage time per iteration:   {avg_iter_time_secs} seconds\")\n",
    "print(\n",
    "    f\"Speedup over baseline:        {avg_iter_time_secs_baseline/avg_iter_time_secs:0.1f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_corrset(data, K, max_iter=1000):\n",
    "    data = data.copy()\n",
    "    data.user = data.user.map({u: i for i, u in enumerate(data.user.unique())})\n",
    "    data.question = data.question.map(\n",
    "        {q: i for i, q in enumerate(data.question.unique())}\n",
    "    )\n",
    "    qs_combinations = itertools.islice(\n",
    "        itertools.combinations(data.question.unique(), K), max_iter\n",
    "    )\n",
    "    users_who_answered_q = np.zeros(\n",
    "        (len(data.question.unique()), len(data.user.unique())), dtype=np.bool_\n",
    "    )\n",
    "    for q, u in data[[\"question\", \"user\"]].itertuples(index=False):\n",
    "        users_who_answered_q[q, u] = True\n",
    "\n",
    "    score_matrix = np.zeros(\n",
    "        (len(data.user.unique()), len(data.question.unique())), dtype=np.float64\n",
    "    )\n",
    "    for q, u, s in data[[\"question\", \"user\", \"score\"]].itertuples(index=False):\n",
    "        score_matrix[u, q] = s\n",
    "\n",
    "    grand_totals = data.groupby(\"user\").score.sum().rename(\"grand_total\").to_dict()\n",
    "    start = time.time()\n",
    "    corrs = compute_corrs(\n",
    "        qs_combinations, users_who_answered_q, score_matrix, grand_totals\n",
    "    )\n",
    "    avg_iter_time_secs = (time.time() - start) / max_iter\n",
    "    corrs = pd.DataFrame(corrs)\n",
    "    return corrs, avg_iter_time_secs\n",
    "\n",
    "\n",
    "def corrcoef(a: list[float], b: list[float]) -> float | None:\n",
    "    \"\"\"same as np.corrcoef(a, b)[0, 1]\"\"\"\n",
    "    n = len(a)\n",
    "    sum_a = sum(a)\n",
    "    sum_b = sum(b)\n",
    "    sum_ab = sum(a_i * b_i for a_i, b_i in zip(a, b))\n",
    "    sum_a_sq = sum(a_i**2 for a_i in a)\n",
    "    sum_b_sq = sum(b_i**2 for b_i in b)\n",
    "    num = n * sum_ab - sum_a * sum_b\n",
    "    den = sqrt(n * sum_a_sq - sum_a**2) * sqrt(n * sum_b_sq - sum_b**2)\n",
    "    if den == 0:\n",
    "        return None\n",
    "    return num / den\n",
    "\n",
    "\n",
    "def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):\n",
    "    result = []\n",
    "    for qs in qs_combinations:\n",
    "        user_sets_for_qs = users_who_answered_q[qs, :]  # numpy indexing\n",
    "        answered_all = np.logical_and.reduce(user_sets_for_qs)\n",
    "        answered_all = np.where(answered_all)[0]\n",
    "        qs_total = score_matrix[answered_all, :][:, qs].sum(axis=1)\n",
    "        user_grand_total = [grand_totals[u] for u in answered_all]\n",
    "        r = corrcoef(qs_total, user_grand_total)\n",
    "        result.append({\"qs\": qs, \"r\": r})\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Running optimization 7 - custom corrcoef\")\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "assert np.allclose(corrs_baseline.r, corrs.r, equal_nan=True)\n",
    "outer_func = lambda: k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "s = profile_func(outer_func, compute_corrs)\n",
    "print(s.strip())\n",
    "print(f\"\\nAverage time per iteration:   {avg_iter_time_secs} seconds\")\n",
    "print(\n",
    "    f\"Speedup over baseline:        {avg_iter_time_secs_baseline/avg_iter_time_secs:0.1f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_corrset(data, K, max_iter=1000):\n",
    "    data = data.copy()\n",
    "    data.user = data.user.map({u: i for i, u in enumerate(data.user.unique())})\n",
    "    data.question = data.question.map(\n",
    "        {q: i for i, q in enumerate(data.question.unique())}\n",
    "    )\n",
    "    qs_combinations = itertools.islice(\n",
    "        itertools.combinations(data.question.unique(), K), max_iter\n",
    "    )\n",
    "    qs_combinations = np.array(list(qs_combinations))\n",
    "    users_who_answered_q = np.zeros(\n",
    "        (len(data.question.unique()), len(data.user.unique())), dtype=np.bool_\n",
    "    )\n",
    "    for q, u in data[[\"question\", \"user\"]].itertuples(index=False):\n",
    "        users_who_answered_q[q, u] = True\n",
    "\n",
    "    score_matrix = np.zeros(\n",
    "        (len(data.user.unique()), len(data.question.unique())), dtype=np.float64\n",
    "    )\n",
    "    for q, u, s in data[[\"question\", \"user\", \"score\"]].itertuples(index=False):\n",
    "        score_matrix[u, q] = s\n",
    "\n",
    "    grand_totals = data.groupby(\"user\").score.sum().rename(\"grand_total\").to_dict()\n",
    "    start = time.time()\n",
    "    corrs = compute_corrs(\n",
    "        qs_combinations, users_who_answered_q, score_matrix, grand_totals\n",
    "    )\n",
    "    avg_iter_time_secs = (time.time() - start) / max_iter\n",
    "    corrs = pd.DataFrame(corrs)\n",
    "    return corrs, avg_iter_time_secs\n",
    "\n",
    "\n",
    "def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):\n",
    "    result = []\n",
    "    for i in range(len(qs_combinations)):\n",
    "        qs = qs_combinations[i]\n",
    "        user_sets_for_qs = users_who_answered_q[qs, :]  # numpy indexing\n",
    "        answered_all = np.logical_and.reduce(user_sets_for_qs)\n",
    "        answered_all = np.where(answered_all)[0]\n",
    "        qs_total = score_matrix[answered_all, :][:, qs].sum(axis=1)\n",
    "        user_grand_total = [grand_totals[u] for u in answered_all]\n",
    "        r = corrcoef(qs_total, user_grand_total)\n",
    "        result.append({\"qs\": qs, \"r\": r})\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Running change 8 - qs as array\")\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "assert np.allclose(corrs_baseline.r, corrs.r, equal_nan=True)\n",
    "outer_func = lambda: k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "s = profile_func(outer_func, compute_corrs)\n",
    "print(s.strip())\n",
    "print(f\"\\nAverage time per iteration:   {avg_iter_time_secs} seconds\")\n",
    "print(\n",
    "    f\"Speedup over baseline:        {avg_iter_time_secs_baseline/avg_iter_time_secs:0.1f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_corrset(data, K, max_iter=1000):\n",
    "    data = data.copy()\n",
    "    data.user = data.user.map({u: i for i, u in enumerate(data.user.unique())})\n",
    "    data.question = data.question.map(\n",
    "        {q: i for i, q in enumerate(data.question.unique())}\n",
    "    )\n",
    "    qs_combinations = itertools.islice(\n",
    "        itertools.combinations(data.question.unique(), K), max_iter\n",
    "    )\n",
    "    qs_combinations = np.array(list(qs_combinations))\n",
    "    users_who_answered_q = np.zeros(\n",
    "        (len(data.question.unique()), len(data.user.unique())), dtype=np.bool_\n",
    "    )\n",
    "    for q, u in data[[\"question\", \"user\"]].itertuples(index=False):\n",
    "        users_who_answered_q[q, u] = True\n",
    "\n",
    "    score_matrix = np.zeros(\n",
    "        (len(data.user.unique()), len(data.question.unique())), dtype=np.float64\n",
    "    )\n",
    "    for q, u, s in data[[\"question\", \"user\", \"score\"]].itertuples(index=False):\n",
    "        score_matrix[u, q] = s\n",
    "\n",
    "    grand_totals = data.groupby(\"user\").score.sum().rename(\"grand_total\").to_dict()\n",
    "    start = time.time()\n",
    "    r_vals = compute_corrs(\n",
    "        qs_combinations, users_who_answered_q, score_matrix, grand_totals\n",
    "    )\n",
    "    avg_iter_time_secs = (time.time() - start) / max_iter\n",
    "    corrs = pd.DataFrame({\"qs\": [tuple(qs) for qs in qs_combinations], \"r\": r_vals})\n",
    "    return corrs, avg_iter_time_secs\n",
    "\n",
    "\n",
    "def corrcoef(a: list[float], b: list[float]) -> float | None:\n",
    "    \"\"\"same as np.corrcoef(a, b)[0, 1]\"\"\"\n",
    "    n = len(a)\n",
    "    sum_a = sum(a)\n",
    "    sum_b = sum(b)\n",
    "    sum_ab = sum(a_i * b_i for a_i, b_i in zip(a, b))\n",
    "    sum_a_sq = sum(a_i**2 for a_i in a)\n",
    "    sum_b_sq = sum(b_i**2 for b_i in b)\n",
    "    num = n * sum_ab - sum_a * sum_b\n",
    "    den = sqrt(n * sum_a_sq - sum_a**2) * sqrt(n * sum_b_sq - sum_b**2)\n",
    "    if den == 0:\n",
    "        return None\n",
    "    return num / den\n",
    "\n",
    "\n",
    "def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):\n",
    "    result = np.empty(len(qs_combinations), dtype=np.float64)\n",
    "    for i in range(len(qs_combinations)):\n",
    "        qs = qs_combinations[i]\n",
    "        user_sets_for_qs = users_who_answered_q[qs, :]  # numpy indexing\n",
    "        answered_all = np.logical_and.reduce(user_sets_for_qs)\n",
    "        answered_all = np.where(answered_all)[0]\n",
    "        qs_total = score_matrix[answered_all, :][:, qs].sum(axis=1)\n",
    "        user_grand_total = [grand_totals[u] for u in answered_all]\n",
    "        result[i] = corrcoef(qs_total, user_grand_total)\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Running change 9 - r as array\")\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "assert np.allclose(corrs_baseline.r, corrs.r, equal_nan=True)\n",
    "outer_func = lambda: k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "s = profile_func(outer_func, compute_corrs)\n",
    "print(s.strip())\n",
    "print(f\"\\nAverage time per iteration:   {avg_iter_time_secs} seconds\")\n",
    "print(\n",
    "    f\"Speedup over baseline:        {avg_iter_time_secs_baseline/avg_iter_time_secs:0.1f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_corrset(data, K, max_iter=1000):\n",
    "    data = data.copy()\n",
    "    data.user = data.user.map({u: i for i, u in enumerate(data.user.unique())})\n",
    "    data.question = data.question.map(\n",
    "        {q: i for i, q in enumerate(data.question.unique())}\n",
    "    )\n",
    "    qs_combinations = itertools.islice(\n",
    "        itertools.combinations(data.question.unique(), K), max_iter\n",
    "    )\n",
    "    qs_combinations = np.array(list(qs_combinations))\n",
    "    users_who_answered_q = np.zeros(\n",
    "        (len(data.question.unique()), len(data.user.unique())), dtype=np.bool_\n",
    "    )\n",
    "    for q, u in data[[\"question\", \"user\"]].itertuples(index=False):\n",
    "        users_who_answered_q[q, u] = True\n",
    "\n",
    "    score_matrix = np.zeros(\n",
    "        (len(data.user.unique()), len(data.question.unique())), dtype=np.float64\n",
    "    )\n",
    "    for q, u, s in data[[\"question\", \"user\", \"score\"]].itertuples(index=False):\n",
    "        score_matrix[u, q] = s\n",
    "\n",
    "    grand_totals = score_matrix.sum(axis=1)\n",
    "\n",
    "    start = time.time()\n",
    "    r_vals = compute_corrs(\n",
    "        qs_combinations, users_who_answered_q, score_matrix, grand_totals\n",
    "    )\n",
    "    avg_iter_time_secs = (time.time() - start) / max_iter\n",
    "    corrs = pd.DataFrame({\"qs\": [tuple(qs) for qs in qs_combinations], \"r\": r_vals})\n",
    "    return corrs, avg_iter_time_secs\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def corrcoef_numba(a, b):\n",
    "    \"\"\"same as np.corrcoef(a, b)[0, 1]\"\"\"\n",
    "    n = len(a)\n",
    "    sum_a = sum(a)\n",
    "    sum_b = sum(b)\n",
    "    sum_ab = sum(a * b)\n",
    "    sum_a_sq = sum(a * a)\n",
    "    sum_b_sq = sum(b * b)\n",
    "    num = n * sum_ab - sum_a * sum_b\n",
    "    den = math.sqrt(n * sum_a_sq - sum_a**2) * math.sqrt(n * sum_b_sq - sum_b**2)\n",
    "    return np.nan if den == 0 else num / den\n",
    "\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):\n",
    "    result = np.empty(len(qs_combinations), dtype=np.float64)\n",
    "    for i in numba.prange(len(qs_combinations)):\n",
    "        qs = qs_combinations[i]\n",
    "        user_sets_for_qs = users_who_answered_q[qs, :]\n",
    "        answered_all = user_sets_for_qs[\n",
    "            0\n",
    "        ]  # numba doesn't support np.logical_and.reduce\n",
    "        for j in range(1, len(user_sets_for_qs)):\n",
    "            answered_all = np.logical_and(answered_all, user_sets_for_qs[j])\n",
    "        answered_all = np.where(answered_all)[0]\n",
    "        qs_total = score_matrix[answered_all, :][:, qs].sum(axis=1)\n",
    "        user_grand_total = grand_totals[answered_all]\n",
    "        result[i] = corrcoef_numba(qs_total, user_grand_total)\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Running optimization 10 - numba, parrallel=True\")\n",
    "k_corrset(data, K=1, max_iter=2)  # let jit happen\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "assert np.allclose(corrs_baseline.r, corrs.r, equal_nan=True)\n",
    "print(f\"\\nAverage time per iteration:   {avg_iter_time_secs} seconds\")\n",
    "print(\n",
    "    f\"Speedup over baseline:        {avg_iter_time_secs_baseline/avg_iter_time_secs:0.1f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(boundscheck=False, fastmath=True, nogil=True)\n",
    "def bitset_create(size):\n",
    "    size_in_int64 = int(np.ceil(size / 64))\n",
    "    return np.zeros(size_in_int64, dtype=np.int64)\n",
    "\n",
    "\n",
    "@numba.njit(boundscheck=False, fastmath=True, nogil=True)\n",
    "def bitset_add(arr, pos):\n",
    "    int64_idx = pos // 64\n",
    "    pos_in_int64 = pos % 64\n",
    "    arr[int64_idx] |= np.int64(1) << np.int64(pos_in_int64)\n",
    "\n",
    "\n",
    "def k_corrset(data, K, max_iter=1000):\n",
    "    data = data.copy()\n",
    "    data[\"user\"] = data[\"user\"].map({u: i for i, u in enumerate(data.user.unique())})\n",
    "    data[\"question\"] = data[\"question\"].map(\n",
    "        {q: i for i, q in enumerate(data.question.unique())}\n",
    "    )\n",
    "\n",
    "    all_qs = data.question.unique()\n",
    "    grand_totals = data.groupby(\"user\").score.sum().values\n",
    "\n",
    "    # create bitsets\n",
    "    users_who_answered_q = np.array(\n",
    "        [bitset_create(data.user.nunique()) for _ in range(data.question.nunique())]\n",
    "    )\n",
    "    for q, u in data[[\"question\", \"user\"]].values:\n",
    "        bitset_add(users_who_answered_q[q], u)\n",
    "\n",
    "    score_matrix = np.zeros(\n",
    "        (data.user.nunique(), data.question.nunique()), dtype=np.int64\n",
    "    )\n",
    "    for row in data.itertuples():\n",
    "        score_matrix[row.user, row.question] = row.score\n",
    "\n",
    "    # todo, would be nice to have a super fast iterator / generator in numba\n",
    "    # rather than creating the whole array\n",
    "    qs_combinations = []\n",
    "    for i, qs in enumerate(itertools.combinations(all_qs, K)):\n",
    "        if i == max_iter:\n",
    "            break\n",
    "        qs_combinations.append(qs)\n",
    "    qs_combinations = np.array(qs_combinations)\n",
    "\n",
    "    start = time.time()\n",
    "    r_vals = compute_corrs(\n",
    "        qs_combinations, users_who_answered_q, score_matrix, grand_totals\n",
    "    )\n",
    "    avg_iter_time_secs = (time.time() - start) / max_iter\n",
    "    corrs = pd.DataFrame({\"qs\": [tuple(qs) for qs in qs_combinations], \"r\": r_vals})\n",
    "    return corrs, avg_iter_time_secs\n",
    "\n",
    "\n",
    "@numba.njit(boundscheck=False, fastmath=True, parallel=False, nogil=True)\n",
    "def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):\n",
    "    num_qs = qs_combinations.shape[0]\n",
    "    bitset_size = users_who_answered_q[0].shape[0]\n",
    "    corrs = np.empty(qs_combinations.shape[0], dtype=np.float64)\n",
    "    for i in numba.prange(num_qs):\n",
    "        # bitset will contain users who answered all questions in qs_array[i]\n",
    "        bitset = users_who_answered_q[qs_combinations[i, 0]].copy()\n",
    "        for q in qs_combinations[i, 1:]:\n",
    "            bitset &= users_who_answered_q[q]\n",
    "        # retrieve stats for the users to compute correlation\n",
    "        n = 0.0\n",
    "        sum_a = 0.0\n",
    "        sum_b = 0.0\n",
    "        sum_ab = 0.0\n",
    "        sum_a_sq = 0.0\n",
    "        sum_b_sq = 0.0\n",
    "        for idx in range(bitset_size):\n",
    "            if bitset[idx] != 0:\n",
    "                for pos in range(64):\n",
    "                    if (bitset[idx] & (np.int64(1) << np.int64(pos))) != 0:\n",
    "                        user_idx = idx * 64 + pos\n",
    "                        score_for_qs = 0.0\n",
    "                        for q in qs_combinations[i]:\n",
    "                            score_for_qs += score_matrix[user_idx, q]\n",
    "                        score_for_user = grand_totals[user_idx]\n",
    "                        n += 1.0\n",
    "                        sum_a += score_for_qs\n",
    "                        sum_b += score_for_user\n",
    "                        sum_ab += score_for_qs * score_for_user\n",
    "                        sum_a_sq += score_for_qs * score_for_qs\n",
    "                        sum_b_sq += score_for_user * score_for_user\n",
    "        num = n * sum_ab - sum_a * sum_b\n",
    "        den = np.sqrt(n * sum_a_sq - sum_a**2) * np.sqrt(n * sum_b_sq - sum_b**2)\n",
    "        corrs[i] = np.nan if den == 0 else num / den\n",
    "    return corrs\n",
    "\n",
    "\n",
    "print(\"Running optimization 11 - numba inline no parallel\")\n",
    "k_corrset(data, K=1, max_iter=2)  # let jit happen\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "assert np.allclose(corrs_baseline.r, corrs.r, equal_nan=True)\n",
    "\n",
    "# Run for longer because so fast\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=1_000_000)\n",
    "print(f\"\\nAverage time per iteration:   {avg_iter_time_secs} seconds\")\n",
    "print(\n",
    "    f\"Speedup over baseline:        {avg_iter_time_secs_baseline/avg_iter_time_secs:0.1f}x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit(boundscheck=False, fastmath=True, nogil=True)\n",
    "def bitset_create(size):\n",
    "    size_in_int64 = int(np.ceil(size / 64))\n",
    "    return np.zeros(size_in_int64, dtype=np.int64)\n",
    "\n",
    "\n",
    "@numba.njit(boundscheck=False, fastmath=True, nogil=True)\n",
    "def bitset_add(arr, pos):\n",
    "    int64_idx = pos // 64\n",
    "    pos_in_int64 = pos % 64\n",
    "    arr[int64_idx] |= np.int64(1) << np.int64(pos_in_int64)\n",
    "\n",
    "\n",
    "def k_corrset(data, K, max_iter=1000):\n",
    "    data = data.copy()\n",
    "    data[\"user\"] = data[\"user\"].map({u: i for i, u in enumerate(data.user.unique())})\n",
    "    data[\"question\"] = data[\"question\"].map(\n",
    "        {q: i for i, q in enumerate(data.question.unique())}\n",
    "    )\n",
    "\n",
    "    all_qs = data.question.unique()\n",
    "    grand_totals = data.groupby(\"user\").score.sum().values\n",
    "\n",
    "    # create bitsets\n",
    "    users_who_answered_q = np.array(\n",
    "        [bitset_create(data.user.nunique()) for _ in range(data.question.nunique())]\n",
    "    )\n",
    "    for q, u in data[[\"question\", \"user\"]].values:\n",
    "        bitset_add(users_who_answered_q[q], u)\n",
    "\n",
    "    score_matrix = np.zeros(\n",
    "        (data.user.nunique(), data.question.nunique()), dtype=np.int64\n",
    "    )\n",
    "    for row in data.itertuples():\n",
    "        score_matrix[row.user, row.question] = row.score\n",
    "\n",
    "    # todo, would be nice to have a super fast iterator / generator in numba\n",
    "    # rather than creating the whole array\n",
    "    qs_combinations = []\n",
    "    for i, qs in enumerate(itertools.combinations(all_qs, K)):\n",
    "        if i == max_iter:\n",
    "            break\n",
    "        qs_combinations.append(qs)\n",
    "    qs_combinations = np.array(qs_combinations)\n",
    "\n",
    "    start = time.time()\n",
    "    r_vals = compute_corrs(\n",
    "        qs_combinations, users_who_answered_q, score_matrix, grand_totals\n",
    "    )\n",
    "    avg_iter_time_secs = (time.time() - start) / max_iter\n",
    "    corrs = pd.DataFrame({\"qs\": [tuple(qs) for qs in qs_combinations], \"r\": r_vals})\n",
    "    return corrs, avg_iter_time_secs\n",
    "\n",
    "\n",
    "@numba.njit(boundscheck=False, fastmath=True, parallel=True, nogil=True)\n",
    "def compute_corrs(qs_combinations, users_who_answered_q, score_matrix, grand_totals):\n",
    "    num_qs = qs_combinations.shape[0]\n",
    "    bitset_size = users_who_answered_q[0].shape[0]\n",
    "    corrs = np.empty(qs_combinations.shape[0], dtype=np.float64)\n",
    "    for i in numba.prange(num_qs):\n",
    "        # bitset will contain users who answered all questions in qs_array[i]\n",
    "        bitset = users_who_answered_q[qs_combinations[i, 0]].copy()\n",
    "        for q in qs_combinations[i, 1:]:\n",
    "            bitset &= users_who_answered_q[q]\n",
    "        # retrieve stats for the users and compute corrcoef\n",
    "        n = 0.0\n",
    "        sum_a = 0.0\n",
    "        sum_b = 0.0\n",
    "        sum_ab = 0.0\n",
    "        sum_a_sq = 0.0\n",
    "        sum_b_sq = 0.0\n",
    "        for idx in range(bitset_size):\n",
    "            if bitset[idx] != 0:\n",
    "                for pos in range(64):\n",
    "                    if (bitset[idx] & (np.int64(1) << np.int64(pos))) != 0:\n",
    "                        user_idx = idx * 64 + pos\n",
    "                        score_for_qs = 0.0\n",
    "                        for q in qs_combinations[i]:\n",
    "                            score_for_qs += score_matrix[user_idx, q]\n",
    "                        score_for_user = grand_totals[user_idx]\n",
    "                        n += 1.0\n",
    "                        sum_a += score_for_qs\n",
    "                        sum_b += score_for_user\n",
    "                        sum_ab += score_for_qs * score_for_user\n",
    "                        sum_a_sq += score_for_qs * score_for_qs\n",
    "                        sum_b_sq += score_for_user * score_for_user\n",
    "        num = n * sum_ab - sum_a * sum_b\n",
    "        den = np.sqrt(n * sum_a_sq - sum_a**2) * np.sqrt(n * sum_b_sq - sum_b**2)\n",
    "        corrs[i] = np.nan if den == 0 else num / den\n",
    "    return corrs\n",
    "\n",
    "\n",
    "print(\"Running optimization 12 - numba inline parallel\")\n",
    "k_corrset(data, K=1, max_iter=2)  # let jit happen\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=MAX_ITER)\n",
    "assert np.allclose(corrs_baseline.r, corrs.r, equal_nan=True)\n",
    "\n",
    "# Run for longer because so fast\n",
    "corrs, avg_iter_time_secs = k_corrset(data, K=5, max_iter=5_000_000)\n",
    "print(f\"\\nAverage time per iteration:   {avg_iter_time_secs} seconds\")\n",
    "print(\n",
    "    f\"Speedup over baseline:        {avg_iter_time_secs_baseline/avg_iter_time_secs:0.1f}x\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
